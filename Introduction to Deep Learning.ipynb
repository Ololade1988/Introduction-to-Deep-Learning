{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77f7e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 22.2.2 from C:\\Users\\Toru\\anaconda3\\lib\\site-packages\\pip (python 3.9)\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip--version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b8b1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\toru\\anaconda3\\lib\\site-packages (22.2.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.1.1-py3-none-any.whl (1.8 MB)\n",
      "     ---------------------------------------- 1.8/1.8 MB 395.0 kB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.2.2\n",
      "    Uninstalling pip-22.2.2:\n",
      "      Successfully uninstalled pip-22.2.2\n",
      "Successfully installed pip-24.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab4811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.2-cp39-cp39-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.16.2 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.16.2-cp39-cp39-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading gast-0.6.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading h5py-3.11.0-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\toru\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (21.3)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading protobuf-4.25.3-cp39-cp39-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\toru\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading grpcio-1.64.1-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "     -------------------------------------- 61.0/61.0 kB 362.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow) (0.37.1)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading optree-0.11.0-cp39-cp39-win_amd64.whl.metadata (46 kB)\n",
      "     -------------------------------------- 46.2/46.2 kB 287.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.3.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\toru\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.16.2->tensorflow) (3.0.9)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.16.2-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.16.2-cp39-cp39-win_amd64.whl (376.9 MB)\n",
      "   ---------------------------------------- 376.9/376.9 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 133.7/133.7 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 57.5/57.5 kB 251.2 kB/s eta 0:00:00\n",
      "Downloading grpcio-1.64.1-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "   ---------------------------------------- 4.1/4.1 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 3.0/3.0 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 1.1/1.1 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 26.4/26.4 MB 1.6 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.3.2-cp39-cp39-win_amd64.whl (127 kB)\n",
      "   -------------------------------------- 127.7/127.7 kB 499.8 kB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 15.8/15.8 MB 1.6 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 65.5/65.5 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.3-cp39-cp39-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 413.4/413.4 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 5.5/5.5 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp39-cp39-win_amd64.whl (240 kB)\n",
      "   ---------------------------------------- 240.0/240.0 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "   ---------------------------------------- 240.7/240.7 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 87.5/87.5 kB 709.1 kB/s eta 0:00:00\n",
      "Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 1.2/1.2 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.6.0-py3-none-any.whl size=21173 sha256=640c80dc239a6d9c5e5837fd2b397af545e9da213d356f005e0fda6ff8530d71\n",
      "  Stored in directory: c:\\users\\toru\\appdata\\local\\pip\\cache\\wheels\\97\\95\\36\\458ee891802c25ad4e9740e8c0ec5c391992ab9f4ce9974713\n",
      "Successfully built gast\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pygments, protobuf, optree, numpy, mdurl, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, opt-einsum, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.7.0\n",
      "    Uninstalling h5py-3.7.0:\n",
      "      Successfully uninstalled h5py-3.7.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.64.1 h5py-3.11.0 keras-3.4.1 libclang-18.1.1 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 numpy-1.26.4 opt-einsum-3.3.0 optree-0.11.0 protobuf-4.25.3 pygments-2.18.0 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 tensorflow-intel-2.16.2 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "spyder 5.2.2 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.4 which is incompatible.\n",
      "scipy 1.9.1 requires numpy<1.25.0,>=1.18.5, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6379e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8682a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\Toru\\\\Desktop\\\\My Project\\\\Introduction-to-Deep-Learning\\\\winequality-red.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c29a8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features and target\n",
    "x = df.copy()\n",
    "y = x.pop(\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ab74ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f89e0ba",
   "metadata": {},
   "source": [
    "# Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dec0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32d32825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toru\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "network = keras.Sequential( [\n",
    "    layers.Dense(units=316, input_shape=[features]), # input layer\n",
    "    layers.Activation(\"relu\"), #activvation to let layer to learn non-linearity\n",
    "    \n",
    "    layers.Dense(units=512),\n",
    "    layers.Activation(\"tanh\"), #first hidden layers\n",
    "    \n",
    "    layers.Dense(units=360),\n",
    "    layers.Activation(\"tanh\"), #second hidden layers\n",
    "    \n",
    "    layers.Dense(units=1,)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a42b07c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasVariable shape=(11, 316), dtype=float32, path=sequential_3/dense_12/kernel>,\n",
       " <KerasVariable shape=(316,), dtype=float32, path=sequential_3/dense_12/bias>,\n",
       " <KerasVariable shape=(316, 512), dtype=float32, path=sequential_3/dense_13/kernel>,\n",
       " <KerasVariable shape=(512,), dtype=float32, path=sequential_3/dense_13/bias>,\n",
       " <KerasVariable shape=(512, 360), dtype=float32, path=sequential_3/dense_14/kernel>,\n",
       " <KerasVariable shape=(360,), dtype=float32, path=sequential_3/dense_14/bias>,\n",
       " <KerasVariable shape=(360, 1), dtype=float32, path=sequential_3/dense_15/kernel>,\n",
       " <KerasVariable shape=(1,), dtype=float32, path=sequential_3/dense_15/bias>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the weight of network\n",
    "network.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670e66a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c33e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff0b6f01",
   "metadata": {},
   "source": [
    "# Compile the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60192f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(loss =\"mae\",optimizer=\"Adam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c6103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac86bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b36e34e",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "708ddb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "189c64a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - loss: 4.4310 - mae: 4.4310 - val_loss: 2.0890 - val_mae: 2.0890\n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.8539 - mae: 1.8539 - val_loss: 1.6645 - val_mae: 1.6645\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.5591 - mae: 1.5591 - val_loss: 0.6542 - val_mae: 0.6542\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.7196 - mae: 0.7196 - val_loss: 1.1165 - val_mae: 1.1165\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.1136 - mae: 1.1136 - val_loss: 0.6136 - val_mae: 0.6136\n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.6262 - mae: 0.6262 - val_loss: 0.9522 - val_mae: 0.9522\n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.9066 - mae: 0.9066 - val_loss: 0.7165 - val_mae: 0.7165\n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6754 - mae: 0.6754 - val_loss: 0.6371 - val_mae: 0.6371\n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6610 - mae: 0.6610 - val_loss: 0.7011 - val_mae: 0.7011\n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.7170 - mae: 0.7170 - val_loss: 0.6489 - val_mae: 0.6489\n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6553 - mae: 0.6553 - val_loss: 0.6728 - val_mae: 0.6728\n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6556 - mae: 0.6556 - val_loss: 0.6724 - val_mae: 0.6724\n",
      "Epoch 13/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.6483 - mae: 0.6483 - val_loss: 0.6527 - val_mae: 0.6527\n",
      "Epoch 14/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.6262 - mae: 0.6262 - val_loss: 0.6247 - val_mae: 0.6247\n",
      "Epoch 15/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5925 - mae: 0.5925 - val_loss: 0.6080 - val_mae: 0.6080\n",
      "Epoch 16/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5967 - mae: 0.5967 - val_loss: 0.6202 - val_mae: 0.6202\n",
      "Epoch 17/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.6075 - mae: 0.6075 - val_loss: 0.6101 - val_mae: 0.6101\n",
      "Epoch 18/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5967 - mae: 0.5967 - val_loss: 0.6003 - val_mae: 0.6003\n",
      "Epoch 19/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5789 - mae: 0.5789 - val_loss: 0.5948 - val_mae: 0.5948\n",
      "Epoch 20/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.5844 - mae: 0.5844 - val_loss: 0.5991 - val_mae: 0.5991\n",
      "Epoch 21/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5850 - mae: 0.5850 - val_loss: 0.5990 - val_mae: 0.5990\n",
      "Epoch 22/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5900 - mae: 0.5900 - val_loss: 0.5956 - val_mae: 0.5956\n",
      "Epoch 23/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5753 - mae: 0.5753 - val_loss: 0.5894 - val_mae: 0.5894\n",
      "Epoch 24/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5770 - mae: 0.5770 - val_loss: 0.5881 - val_mae: 0.5881\n",
      "Epoch 25/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5778 - mae: 0.5778 - val_loss: 0.5916 - val_mae: 0.5916\n",
      "Epoch 26/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5803 - mae: 0.5803 - val_loss: 0.5862 - val_mae: 0.5862\n",
      "Epoch 27/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5687 - mae: 0.5687 - val_loss: 0.5836 - val_mae: 0.5836\n",
      "Epoch 28/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5711 - mae: 0.5711 - val_loss: 0.5890 - val_mae: 0.5890\n",
      "Epoch 29/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5731 - mae: 0.5731 - val_loss: 0.5826 - val_mae: 0.5826\n",
      "Epoch 30/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5662 - mae: 0.5662 - val_loss: 0.5826 - val_mae: 0.5826\n",
      "Epoch 31/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5641 - mae: 0.5641 - val_loss: 0.5815 - val_mae: 0.5815\n",
      "Epoch 32/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5626 - mae: 0.5626 - val_loss: 0.5819 - val_mae: 0.5819\n",
      "Epoch 33/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5650 - mae: 0.5650 - val_loss: 0.5802 - val_mae: 0.5802\n",
      "Epoch 34/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5606 - mae: 0.5606 - val_loss: 0.5798 - val_mae: 0.5798\n",
      "Epoch 35/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5619 - mae: 0.5619 - val_loss: 0.5800 - val_mae: 0.5800\n",
      "Epoch 36/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5568 - mae: 0.5568 - val_loss: 0.5811 - val_mae: 0.5811\n",
      "Epoch 37/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5507 - mae: 0.5507 - val_loss: 0.5800 - val_mae: 0.5800\n",
      "Epoch 38/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5586 - mae: 0.5586 - val_loss: 0.5825 - val_mae: 0.5825\n",
      "Epoch 39/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5585 - mae: 0.5585 - val_loss: 0.5856 - val_mae: 0.5856\n",
      "Epoch 40/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5652 - mae: 0.5652 - val_loss: 0.5962 - val_mae: 0.5962\n",
      "Epoch 41/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5683 - mae: 0.5683 - val_loss: 0.5786 - val_mae: 0.5786\n",
      "Epoch 42/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5513 - mae: 0.5513 - val_loss: 0.5812 - val_mae: 0.5812\n",
      "Epoch 43/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5532 - mae: 0.5532 - val_loss: 0.6134 - val_mae: 0.6134\n",
      "Epoch 44/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5802 - mae: 0.5802 - val_loss: 0.5809 - val_mae: 0.5809\n",
      "Epoch 45/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.5568 - mae: 0.5568 - val_loss: 0.5806 - val_mae: 0.5806\n",
      "Epoch 46/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5530 - mae: 0.5530 - val_loss: 0.5900 - val_mae: 0.5900\n",
      "Epoch 47/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5554 - mae: 0.5554 - val_loss: 0.5921 - val_mae: 0.5921\n",
      "Epoch 48/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5645 - mae: 0.5645 - val_loss: 0.5963 - val_mae: 0.5963\n",
      "Epoch 49/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5633 - mae: 0.5633 - val_loss: 0.5784 - val_mae: 0.5784\n",
      "Epoch 50/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5586 - mae: 0.5586 - val_loss: 0.5793 - val_mae: 0.5793\n",
      "Epoch 51/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.5491 - mae: 0.5491 - val_loss: 0.5740 - val_mae: 0.5740\n",
      "Epoch 52/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.5422 - mae: 0.5422 - val_loss: 0.5721 - val_mae: 0.5721\n",
      "Epoch 53/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.5438 - mae: 0.5438 - val_loss: 0.5769 - val_mae: 0.5769\n",
      "Epoch 54/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5497 - mae: 0.5497 - val_loss: 0.5690 - val_mae: 0.5690\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5377 - mae: 0.5377 - val_loss: 0.5807 - val_mae: 0.5807\n",
      "Epoch 56/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5458 - mae: 0.5458 - val_loss: 0.5699 - val_mae: 0.5699\n",
      "Epoch 57/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5354 - mae: 0.5354 - val_loss: 0.5827 - val_mae: 0.5827\n",
      "Epoch 58/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5459 - mae: 0.5459 - val_loss: 0.5621 - val_mae: 0.5621\n",
      "Epoch 59/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5265 - mae: 0.5265 - val_loss: 0.5663 - val_mae: 0.5663\n",
      "Epoch 60/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5325 - mae: 0.5325 - val_loss: 0.5584 - val_mae: 0.5584\n",
      "Epoch 61/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5198 - mae: 0.5198 - val_loss: 0.5538 - val_mae: 0.5538\n",
      "Epoch 62/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5243 - mae: 0.5243 - val_loss: 0.5654 - val_mae: 0.5654\n",
      "Epoch 63/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5193 - mae: 0.5193 - val_loss: 0.5643 - val_mae: 0.5643\n",
      "Epoch 64/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5187 - mae: 0.5187 - val_loss: 0.5487 - val_mae: 0.5487\n",
      "Epoch 65/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5264 - mae: 0.5264 - val_loss: 0.5510 - val_mae: 0.5510\n",
      "Epoch 66/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.5314 - mae: 0.5314 - val_loss: 0.5496 - val_mae: 0.5496\n",
      "Epoch 67/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5117 - mae: 0.5117 - val_loss: 0.5418 - val_mae: 0.5418\n",
      "Epoch 68/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.5195 - mae: 0.5195 - val_loss: 0.5938 - val_mae: 0.5938\n",
      "Epoch 69/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5409 - mae: 0.5409 - val_loss: 0.5546 - val_mae: 0.5546\n",
      "Epoch 70/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5334 - mae: 0.5334 - val_loss: 0.5645 - val_mae: 0.5645\n",
      "Epoch 71/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5256 - mae: 0.5256 - val_loss: 0.5353 - val_mae: 0.5353\n",
      "Epoch 72/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5064 - mae: 0.5064 - val_loss: 0.5396 - val_mae: 0.5396\n",
      "Epoch 73/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5094 - mae: 0.5094 - val_loss: 0.5352 - val_mae: 0.5352\n",
      "Epoch 74/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5055 - mae: 0.5055 - val_loss: 0.5331 - val_mae: 0.5331\n",
      "Epoch 75/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5019 - mae: 0.5019 - val_loss: 0.5394 - val_mae: 0.5394\n",
      "Epoch 76/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.5059 - mae: 0.5059 - val_loss: 0.5541 - val_mae: 0.5541\n",
      "Epoch 77/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5118 - mae: 0.5118 - val_loss: 0.5356 - val_mae: 0.5356\n",
      "Epoch 78/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5204 - mae: 0.5204 - val_loss: 0.5345 - val_mae: 0.5345\n",
      "Epoch 79/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5115 - mae: 0.5115 - val_loss: 0.5504 - val_mae: 0.5504\n",
      "Epoch 80/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.5091 - mae: 0.5091 - val_loss: 0.5326 - val_mae: 0.5326\n",
      "Epoch 81/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5002 - mae: 0.5002 - val_loss: 0.5295 - val_mae: 0.5295\n",
      "Epoch 82/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5006 - mae: 0.5006 - val_loss: 0.5304 - val_mae: 0.5304\n",
      "Epoch 83/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4971 - mae: 0.4971 - val_loss: 0.5701 - val_mae: 0.5701\n",
      "Epoch 84/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5172 - mae: 0.5172 - val_loss: 0.5417 - val_mae: 0.5417\n",
      "Epoch 85/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5233 - mae: 0.5233 - val_loss: 0.5482 - val_mae: 0.5482\n",
      "Epoch 86/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5018 - mae: 0.5018 - val_loss: 0.5307 - val_mae: 0.5307\n",
      "Epoch 87/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5211 - mae: 0.5211 - val_loss: 0.5408 - val_mae: 0.5408\n",
      "Epoch 88/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.5294 - mae: 0.5294 - val_loss: 0.6115 - val_mae: 0.6115\n",
      "Epoch 89/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5595 - mae: 0.5595 - val_loss: 0.5290 - val_mae: 0.5290\n",
      "Epoch 90/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.5078 - mae: 0.5078 - val_loss: 0.5733 - val_mae: 0.5733\n",
      "Epoch 91/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.5212 - mae: 0.5212 - val_loss: 0.5438 - val_mae: 0.5438\n",
      "Epoch 92/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5332 - mae: 0.5332 - val_loss: 0.5344 - val_mae: 0.5344\n",
      "Epoch 93/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4979 - mae: 0.4979 - val_loss: 0.5462 - val_mae: 0.5462\n",
      "Epoch 94/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5085 - mae: 0.5085 - val_loss: 0.5231 - val_mae: 0.5231\n",
      "Epoch 95/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4989 - mae: 0.4989 - val_loss: 0.5316 - val_mae: 0.5316\n",
      "Epoch 96/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4904 - mae: 0.4904 - val_loss: 0.5338 - val_mae: 0.5338\n",
      "Epoch 97/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4863 - mae: 0.4863 - val_loss: 0.5305 - val_mae: 0.5305\n",
      "Epoch 98/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5053 - mae: 0.5053 - val_loss: 0.5291 - val_mae: 0.5291\n",
      "Epoch 99/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4855 - mae: 0.4855 - val_loss: 0.5221 - val_mae: 0.5221\n",
      "Epoch 100/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4906 - mae: 0.4906 - val_loss: 0.5224 - val_mae: 0.5224\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = network.fit(x = x_train, y = y_train, validation_data=(x_val, y_val), batch_size=900,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9301d611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e2de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b64ebb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bdb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f306de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f68eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
